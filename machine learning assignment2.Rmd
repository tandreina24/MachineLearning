---
title: "Machine Learning Assignment Project"
author: "Andreina Torres"
date: "25 de marzo de 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Summary
One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, the  goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to predict the manner in which they did the exercise. 

We are going to predict is the "classe" variable using any of the other variables that describe performance. 

This report describe how the model where build, how we used cross validation, what we think about the expected out of sample error is, and why we made this choices. We will also use your prediction model to predict 20 different test cases.

##0-Packages
```{r package}
library(caret)
library(knitr)
library(rpart)
library(randomForest)

set.seed(12345)

```

##1-Data 
The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. 

The data base include 160 variables, which are:
The classe variable wich have 5 categories (A,B,C,D,E) and a group of continuous variables that record the user preformance in different aspects.

Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes. Participants were supervised by an experienced weight lifter to make sure the execution complied to the manner they were supposed to simulate. The exercises were performed by six male participants aged between 20-28 years, with little weight lifting experience, all participants could easily simulate the mistakes in a safe and controlled manner by using a relatively light dumbbell (1.25kg).

*Exactly according to the specification (Class A), 
*Throwing the elbows to the front (Class B), 
*Lifting the dumbbell only halfway (Class C), 
*lowering the dumbbell only halfway (Class D),
*Throwing the hips to the front (Class E).

Read more: http://groupware.les.inf.puc-rio.br/har#ixzz4cLuKQXrW

```{r data}

training <-read.csv("C:/Users/AndreinaDeJ/Documents/Andreina Torres/Academico/coursera/cursos y cursera/Coursera/data scientits specialization/8-Practical machine learning/assigment/pml-training.csv",na.strings = c("NA","#DIV/0!",""))
testing <-read.csv("C:/Users/AndreinaDeJ/Documents/Andreina Torres/Academico/coursera/cursos y cursera/Coursera/data scientits specialization/8-Practical machine learning/assigment/pml-testing.csv",na.strings = c("NA","#DIV/0!",""))

```


##2-Data cleaning
We create a new data set that contains the variables that will be used in the model. Therefore, the following variables were removed: variables without variance, variables with more that a 50% of records with missing values, unnecessary variables.

```{r cleaning}

#Delete variables without variance
nzv <- nearZeroVar(training, saveMetrics=TRUE)
training2 <- training[,nzv$nzv==FALSE]

#Delete users names (unnecessary) 
training2 <- training2[,-c(1,2,5)]
#training2<-training2[,-c(1,4)]

#Delete less than 50% missings
training2 <- training2[colSums(is.na(training2))/nrow(training2) < .5]


#keep the necessary variables in the testing file
vtraining2<-training2[,-56]
varnames <- colnames(vtraining2)
testing2 <-testing[varnames]

testing2$magnet_dumbbell_z=as.numeric(testing2$magnet_dumbbell_z)
testing2$magnet_forearm_y=as.numeric(testing2$magnet_forearm_y)
testing2$magnet_forearm_z=as.numeric(testing2$magnet_forearm_z)

```

##3-Descriptive
The file has similar counts in each classe type.

```{r descriptive}
plot(training$classe, xlab="Classe type")
```

##4-Cross validation using random subsampling
The training data was splited to create a ramdon subsampling set to do cross validation.

```{r crossvalidation}
inTrain = createDataPartition(training2$classe, p = 0.7)[[1]]
subtraining = training2[ inTrain,]
subtesting = training2[-inTrain,]
```

##5-Modeling
It was used three diferent types of models to check which one report the highest accuracy. 

##5.1 Regresion Tree
```{r CTree}
modFit1<-rpart(classe ~.,data=subtraining)
rpart.plot::rpart.plot(modFit1)

pred1<-predict(modFit1, subtesting, type = "class")
CM1<-confusionMatrix(pred1, subtesting$classe)
CM1$overall

CM1
```

##5.2 Lineal Discriminant Analysis
```{r Discriminant}
modFit2<-train(classe ~.,data=subtraining, method="lda")

pred2<-predict(modFit2, subtesting)
CM2<-confusionMatrix(pred2, subtesting$classe)
CM2$overall


CM2
```


##5.3 Random Forest
```{r RF}
modFit3 <- randomForest(classe ~ ., data=subtraining, method="class")

pred3 <- predict(modFit3, subtesting, type = "class")
CM3<-confusionMatrix(pred3, subtesting$class)
CM3$overall


CM3
```

#Conclusion
##Model selection and prediction
The Random forest model was the one tha report the highest accuaracy (0.9986). the sample error expectec to be is estimated at 0.0014, or 0.14%. 
Therefore, we predict the testing values using this model getting the following prediction.

```{r prediction}
prediction <- predict(modFit3, testing2, type = "class")
prediction
```




